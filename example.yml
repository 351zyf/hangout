inputs:
    - Kafka:
        codec: plain
        topic: 
          app: 2
        consumer_settings:
          group.id: hangout
          zookeeper.connect: 192.168.1.200:2181
          auto.commit.interval.ms: "1000"
          socket.receive.buffer.bytes: "1048576"
          fetch.message.max.bytes: "1048576"
          num.consumer.fetchers: "4"
    - Kafka:
        codec: json
        topic: 
          web: 1
        consumer_settings:
          group.id: hangout
          zookeeper.connect: 192.168.1.201:2181
          auto.commit.interval.ms: "5000"

filters:
    - Grok:
        threads: 4
        src: message
        match:
          - '^(?<logtime>\S+) (?<user>.+) (-|(?<level>\w+)) %{DATA:msg}$'
        remove_fields: ['message']
    - Add:
        threads: 4
        fields:
            test: 'abcd'
        if:
          - '<#if message??>true</#if>'
          - '<#if message?contains("liu")>true<#elseif message?contains("warn")>true</#if>'
    - Date:
        src: logtime
        formats:
            - 'ISO8601'
        remove_fields: ['logtime']
    - Lowercase:
        fields: ['user']
    - Add:
        fields:
          me: 'I am ${user}'
    - Remove:
        fields:
          - logtime
    - Trim:
        fields:
          - user
    - Rename:
        fields:
          me: he
          user: she
    - Gsub:
        threads: 4
        fields:
          she: ['c','CCC']
          he: ['(^\w+)|(\w+$)','XXX']
    - Translate:
        source: ServiceCode
        target: soaurl
        dictionary_path: /tmp/app.dic
    - KV:
        source: msg
        target: kv
        field_split: ' '
        value_split: '='
        trim: '\t\"'
        trimkey: '\"'
        tag_on_failure: "KVfail"
        remove_fields: ['msg']

outputs:
    - Elasticsearch:
        threads: 1
        cluster: hangoutcluster
        hosts:
          - 192.168.1.200
        index: 'hangout-${@timestamp.toString("YYYY.MM.dd")}'
        index_type: logs # default logs
        bulk_actions: 20000 #default 20000
        bulk_size: 15 # default 15 MB
        flush_interval: 10 # default 10 seconds
        concurrent_requests: 1 # default 1
    - Kafka:
        threads: 1
        broker_list: 192.168.1.200:9092
        topic: test2
    - Stdout: {}
        threads: 1
